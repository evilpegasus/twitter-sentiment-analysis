{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Twitter Sentiment Analysis\n",
    "Ming Fong\n",
    "\n",
    "Linguistics 55AC\n",
    "\n",
    "Useful: https://medium.com/swlh/coronavirus-python-tutorial-1-520cc960aac1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy #https://github.com/tweepy/tweepy\n",
    "import csv\n",
    "from secrets import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = api_key\n",
    "consumer_secret = api_secret\n",
    "access_key = access_token\n",
    "access_secret = access_secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_tweets(screen_name):\n",
    "    #Twitter only allows access to a users most recent 3240 tweets with this method\n",
    "    \n",
    "    #authorize twitter, initialize tweepy\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_key, access_secret)\n",
    "    api = tweepy.API(auth)\n",
    "    \n",
    "    #initialize a list to hold all the tweepy Tweets\n",
    "    alltweets = []  \n",
    "    \n",
    "    #make initial request for most recent tweets (200 is the maximum allowed count)\n",
    "    new_tweets = api.user_timeline(screen_name = screen_name, count = 200)\n",
    "    \n",
    "    #save most recent tweets\n",
    "    alltweets.extend(new_tweets)\n",
    "    \n",
    "    #save the id of the oldest tweet less one\n",
    "    oldest = alltweets[-1].id - 1\n",
    "    \n",
    "    #keep grabbing tweets until there are no tweets left to grab\n",
    "    while len(new_tweets) > 0:\n",
    "        print(f\"getting tweets before {oldest}\")\n",
    "        \n",
    "        #all subsiquent requests use the max_id param to prevent duplicates\n",
    "        new_tweets = api.user_timeline(screen_name = screen_name, count=200, max_id = oldest)\n",
    "        \n",
    "        #save most recent tweets\n",
    "        alltweets.extend(new_tweets)\n",
    "        \n",
    "        #update the id of the oldest tweet less one\n",
    "        oldest = alltweets[-1].id - 1\n",
    "        \n",
    "        print(f\"...{len(alltweets)} tweets downloaded so far\")\n",
    "    \n",
    "    #transform the tweepy tweets into a 2D array that will populate the csv \n",
    "    outtweets = [[tweet.id_str, tweet.created_at, tweet.text] for tweet in alltweets]\n",
    "    \n",
    "    #write the csv  \n",
    "    # with open(f'data/{screen_name}_tweets.csv', 'w') as f:\n",
    "    #     writer = csv.writer(f)\n",
    "    #     writer.writerow([\"id\",\"created_at\",\"text\"])\n",
    "    #     writer.writerows(outtweets)\n",
    "    \n",
    "    return outtweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "getting tweets before 1334858997367771136\n",
      "...400 tweets downloaded so far\n",
      "getting tweets before 1331757781658034177\n",
      "...599 tweets downloaded so far\n",
      "getting tweets before 1329064787142172672\n",
      "...797 tweets downloaded so far\n",
      "getting tweets before 1326910477587374080\n",
      "...997 tweets downloaded so far\n",
      "getting tweets before 1324061986779504641\n",
      "...1197 tweets downloaded so far\n",
      "getting tweets before 1322656588285407233\n",
      "...1397 tweets downloaded so far\n",
      "getting tweets before 1321231434271592455\n",
      "...1597 tweets downloaded so far\n",
      "getting tweets before 1320163234926764031\n",
      "...1797 tweets downloaded so far\n",
      "getting tweets before 1318205801555787780\n",
      "...1995 tweets downloaded so far\n",
      "getting tweets before 1316669409616965631\n",
      "...2192 tweets downloaded so far\n",
      "getting tweets before 1315659918469402623\n",
      "...2392 tweets downloaded so far\n",
      "getting tweets before 1313832209317494785\n",
      "...2590 tweets downloaded so far\n",
      "getting tweets before 1311454419838525441\n",
      "...2790 tweets downloaded so far\n",
      "getting tweets before 1309624557897240575\n",
      "...2990 tweets downloaded so far\n",
      "getting tweets before 1308153832191401983\n",
      "...3187 tweets downloaded so far\n",
      "getting tweets before 1305623700587253760\n",
      "...3200 tweets downloaded so far\n",
      "getting tweets before 1305613921772908543\n",
      "...3200 tweets downloaded so far\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(get_all_tweets(\"realDonaldTrump\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove links\n",
    "df[2] = [re.sub(r'http\\S+', '', str(x)) for x in df[2]]\n",
    "# Remove Retweets\n",
    "df = df[~df[2].str.startswith(\"RT @\")]\n",
    "df[2] = df[2].replace(\"\", np.nan)\n",
    "df = df.dropna(subset = [2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}